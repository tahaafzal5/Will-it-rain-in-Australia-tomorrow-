{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv(r'D:\\Augustana University\\Courses\\5. Spring 2020\\COSC 380-A Artificial Intelligence & Robotics\\Projects\\Final Project\\Final Final\\weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145460, 24)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-12-06</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>56.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>28.9</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>50.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1009.6</td>\n",
       "      <td>1008.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-12-08</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>35.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008-12-09</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.7</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>80.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>1003.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>No</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>28.0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1005.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1</td>\n",
       "      <td>28.2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "5  2008-12-06   Albury     14.6     29.7       0.2          NaN       NaN   \n",
       "6  2008-12-07   Albury     14.3     25.0       0.0          NaN       NaN   \n",
       "7  2008-12-08   Albury      7.7     26.7       0.0          NaN       NaN   \n",
       "8  2008-12-09   Albury      9.7     31.9       0.0          NaN       NaN   \n",
       "9  2008-12-10   Albury     13.1     30.1       1.4          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "5         WNW           56.0          W  ...        23.0       1009.2   \n",
       "6           W           50.0         SW  ...        19.0       1009.6   \n",
       "7           W           35.0        SSE  ...        19.0       1013.4   \n",
       "8         NNW           80.0         SE  ...         9.0       1008.9   \n",
       "9           W           28.0          S  ...        27.0       1007.0   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
       "5       1005.4       NaN       NaN     20.6     28.9         No      0.0   \n",
       "6       1008.2       1.0       NaN     18.1     24.6         No      0.0   \n",
       "7       1010.1       NaN       NaN     16.3     25.5         No      0.0   \n",
       "8       1003.6       NaN       NaN     18.3     30.2         No      1.4   \n",
       "9       1005.7       NaN       NaN     20.1     28.2        Yes      0.0   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "5            No  \n",
       "6            No  \n",
       "7            No  \n",
       "8           Yes  \n",
       "9            No  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**: The date of observation<br/>\n",
    "**Location:** The common name of the location of the weather station<br/>\n",
    "**MinTemp:** The minimum temperature in degrees celsius<br/>\n",
    "**MaxTemp:** The maximum temperature in degrees celsius<br/>\n",
    "**Rainfall:** The amount of rainfall recorded for the day in mm<br/>\n",
    "**Evaporation:** The so-called Class A pan evaporation (mm) in the 24 hours to 9am<br/>\n",
    "**Sunshine:** The number of hours of bright sunshine in the day.<br/>\n",
    "**WindGustDir:** The direction of the strongest wind gust in the 24 hours to midnight<br/>\n",
    "**WindGustSpeed:** The speed (km/h) of the strongest wind gust in the 24 hours to midnight<br/>\n",
    "**WindDir9am:** Direction of the wind at 9am<br/>\n",
    "**WindDir3pm:** Direction of the wind at 3pm<br/>\n",
    "**WindSpeed9am:** Wind speed (km/hr) averaged over 10 minutes prior to 9am<br/>\n",
    "**WindSpeed3pm:** Wind speed (km/hr) averaged over 10 minutes prior to 3pm<br/>\n",
    "**Humidity9am:** Humidity (percent) at 9am<br/>\n",
    "**Humidity3pm:** Humidity (percent) at 3pm<br/>\n",
    "**Pressure9am:** Atmospheric pressure (hpa) reduced to mean sea level at 9am<br/>\n",
    "**Pressure3pm:** Atmospheric pressure (hpa) reduced to mean sea level at 3pm<br/>\n",
    "**Cloud9am:** Fraction of sky obscured by cloud at 9am. This is measured in oktas, which are a unit of eigths. It records how many<br/>\n",
    "**Cloud3pm:** Fraction of sky obscured by cloud at 3pm. This is measured in oktas, which are a unit of eigths. It records how many<br/>\n",
    "**Temp9am:** Temperature (degrees C) at 9am<br/>\n",
    "**Temp3pm:** Temperature (degrees C) at 9am<br/>\n",
    "**RainToday:** Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0<br/>\n",
    "**RISK_MM:** The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\".<br/>\n",
    "**RainTomorrow:** The target variable. Did it rain tomorrow?<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RISK_MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143975.000000</td>\n",
       "      <td>144199.000000</td>\n",
       "      <td>142199.000000</td>\n",
       "      <td>82670.000000</td>\n",
       "      <td>75625.000000</td>\n",
       "      <td>135197.000000</td>\n",
       "      <td>143693.000000</td>\n",
       "      <td>142398.000000</td>\n",
       "      <td>142806.000000</td>\n",
       "      <td>140953.000000</td>\n",
       "      <td>130395.00000</td>\n",
       "      <td>130432.000000</td>\n",
       "      <td>89572.000000</td>\n",
       "      <td>86102.000000</td>\n",
       "      <td>143693.000000</td>\n",
       "      <td>141851.00000</td>\n",
       "      <td>142193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.194034</td>\n",
       "      <td>23.221348</td>\n",
       "      <td>2.360918</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>40.035230</td>\n",
       "      <td>14.043426</td>\n",
       "      <td>18.662657</td>\n",
       "      <td>68.880831</td>\n",
       "      <td>51.539116</td>\n",
       "      <td>1017.64994</td>\n",
       "      <td>1015.255889</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.509930</td>\n",
       "      <td>16.990631</td>\n",
       "      <td>21.68339</td>\n",
       "      <td>2.360682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.398495</td>\n",
       "      <td>7.119049</td>\n",
       "      <td>8.478060</td>\n",
       "      <td>4.193704</td>\n",
       "      <td>3.785483</td>\n",
       "      <td>13.607062</td>\n",
       "      <td>8.915375</td>\n",
       "      <td>8.809800</td>\n",
       "      <td>19.029164</td>\n",
       "      <td>20.795902</td>\n",
       "      <td>7.10653</td>\n",
       "      <td>7.037414</td>\n",
       "      <td>2.887159</td>\n",
       "      <td>2.720357</td>\n",
       "      <td>6.488753</td>\n",
       "      <td>6.93665</td>\n",
       "      <td>8.477969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.50000</td>\n",
       "      <td>977.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.200000</td>\n",
       "      <td>-5.40000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1012.90000</td>\n",
       "      <td>1010.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.60000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1017.60000</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>21.10000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.40000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.40000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.00000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>46.70000</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
       "count  143975.000000  144199.000000  142199.000000  82670.000000   \n",
       "mean       12.194034      23.221348       2.360918      5.468232   \n",
       "std         6.398495       7.119049       8.478060      4.193704   \n",
       "min        -8.500000      -4.800000       0.000000      0.000000   \n",
       "25%         7.600000      17.900000       0.000000      2.600000   \n",
       "50%        12.000000      22.600000       0.000000      4.800000   \n",
       "75%        16.900000      28.200000       0.800000      7.400000   \n",
       "max        33.900000      48.100000     371.000000    145.000000   \n",
       "\n",
       "           Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\n",
       "count  75625.000000  135197.000000  143693.000000  142398.000000   \n",
       "mean       7.611178      40.035230      14.043426      18.662657   \n",
       "std        3.785483      13.607062       8.915375       8.809800   \n",
       "min        0.000000       6.000000       0.000000       0.000000   \n",
       "25%        4.800000      31.000000       7.000000      13.000000   \n",
       "50%        8.400000      39.000000      13.000000      19.000000   \n",
       "75%       10.600000      48.000000      19.000000      24.000000   \n",
       "max       14.500000     135.000000     130.000000      87.000000   \n",
       "\n",
       "         Humidity9am    Humidity3pm   Pressure9am    Pressure3pm  \\\n",
       "count  142806.000000  140953.000000  130395.00000  130432.000000   \n",
       "mean       68.880831      51.539116    1017.64994    1015.255889   \n",
       "std        19.029164      20.795902       7.10653       7.037414   \n",
       "min         0.000000       0.000000     980.50000     977.100000   \n",
       "25%        57.000000      37.000000    1012.90000    1010.400000   \n",
       "50%        70.000000      52.000000    1017.60000    1015.200000   \n",
       "75%        83.000000      66.000000    1022.40000    1020.000000   \n",
       "max       100.000000     100.000000    1041.00000    1039.600000   \n",
       "\n",
       "           Cloud9am      Cloud3pm        Temp9am       Temp3pm        RISK_MM  \n",
       "count  89572.000000  86102.000000  143693.000000  141851.00000  142193.000000  \n",
       "mean       4.447461      4.509930      16.990631      21.68339       2.360682  \n",
       "std        2.887159      2.720357       6.488753       6.93665       8.477969  \n",
       "min        0.000000      0.000000      -7.200000      -5.40000       0.000000  \n",
       "25%        1.000000      2.000000      12.300000      16.60000       0.000000  \n",
       "50%        5.000000      5.000000      16.700000      21.10000       0.000000  \n",
       "75%        7.000000      7.000000      21.600000      26.40000       0.800000  \n",
       "max        9.000000      9.000000      40.200000      46.70000     371.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels = ['Date', 'Location', 'RISK_MM'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Yes by 1 and No by 0 for RainToday and RainTomorrow columns\n",
    "\n",
    "df['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "df['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['W', 'WNW', 'WSW', 'NE', 'NNW', 'N', 'NNE', 'SW', nan, 'ENE',\n",
       "       'SSE', 'S', 'NW', 'SE', 'ESE', 'E', 'SSW'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WindGustDir'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindGustDir'].replace({'W': 1, 'WNW': 2, 'WSW': 3, 'NE': 4, 'NNW':5, 'N':6, 'NNE': 7, 'SW': 8,\n",
    "                          'ENE':9, 'SSE': 10, 'S': 11, 'NW': 12, 'SE':13, 'ESE':14,\n",
    "                          'E': 15, 'SSW':16}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "\n",
    "#f, ax = plt.subplots(figsize=(20, 15))\n",
    "#corr = df.corr()\n",
    "#sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "#            square=True, ax=ax, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['WindDir3pm', 'WindDir9am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dummy variables for categorical predictors\n",
    "\n",
    "df = pd.get_dummies(df, columns = categorical, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58080, 49)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting rid of nan values\n",
    "\n",
    "df = df.dropna(how = 'any')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scale = preprocessing.MinMaxScaler()\n",
    "scale.fit(df)\n",
    "\n",
    "df = pd.DataFrame(scale.transform(df), index = df.index, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir9am_NNW</th>\n",
       "      <th>WindDir9am_NW</th>\n",
       "      <th>WindDir9am_S</th>\n",
       "      <th>WindDir9am_SE</th>\n",
       "      <th>WindDir9am_SSE</th>\n",
       "      <th>WindDir9am_SSW</th>\n",
       "      <th>WindDir9am_SW</th>\n",
       "      <th>WindDir9am_W</th>\n",
       "      <th>WindDir9am_WNW</th>\n",
       "      <th>WindDir9am_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>0.645669</td>\n",
       "      <td>0.706818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>0.848276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339130</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>0.658793</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182266</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133005</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>0.750656</td>\n",
       "      <td>0.779545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140394</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.838636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.579310</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142298</th>\n",
       "      <td>0.682415</td>\n",
       "      <td>0.665909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073892</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142299</th>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093596</td>\n",
       "      <td>0.593103</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.194030</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142300</th>\n",
       "      <td>0.719160</td>\n",
       "      <td>0.652273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142301</th>\n",
       "      <td>0.687664</td>\n",
       "      <td>0.629545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.147826</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.223684</td>\n",
       "      <td>0.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142302</th>\n",
       "      <td>0.706037</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.182609</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58080 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
       "6049    0.645669  0.706818       0.0     0.147783  0.848276     1.000000   \n",
       "6050    0.658793  0.563636       0.0     0.182266  0.896552     0.666667   \n",
       "6052    0.685039  0.761364       0.0     0.133005  0.731034     0.400000   \n",
       "6053    0.750656  0.779545       0.0     0.140394  0.841379     0.066667   \n",
       "6054    0.811024  0.838636       0.0     0.137931  0.579310     0.066667   \n",
       "...          ...       ...       ...          ...       ...          ...   \n",
       "142298  0.682415  0.665909       0.0     0.073892  0.758621     0.533333   \n",
       "142299  0.732283  0.647727       0.0     0.093596  0.593103     0.933333   \n",
       "142300  0.719160  0.652273       0.0     0.068966  0.758621     0.933333   \n",
       "142301  0.687664  0.629545       0.0     0.076355  0.731034     0.866667   \n",
       "142302  0.706037  0.627273       0.0     0.068966  0.737931     0.533333   \n",
       "\n",
       "        WindGustSpeed  WindSpeed9am  WindSpeed3pm  Humidity9am  ...  \\\n",
       "6049         0.339130      0.089552      0.263158         0.20  ...   \n",
       "6050         0.243478      0.283582      0.250000         0.30  ...   \n",
       "6052         0.321739      0.447761      0.197368         0.42  ...   \n",
       "6053         0.191304      0.089552      0.078947         0.37  ...   \n",
       "6054         0.226087      0.253731      0.171053         0.19  ...   \n",
       "...               ...           ...           ...          ...  ...   \n",
       "142298       0.226087      0.134328      0.263158         0.63  ...   \n",
       "142299       0.243478      0.194030      0.144737         0.56  ...   \n",
       "142300       0.208696      0.253731      0.144737         0.46  ...   \n",
       "142301       0.147826      0.134328      0.223684         0.62  ...   \n",
       "142302       0.182609      0.223881      0.092105         0.73  ...   \n",
       "\n",
       "        WindDir9am_NNW  WindDir9am_NW  WindDir9am_S  WindDir9am_SE  \\\n",
       "6049               0.0            0.0           0.0            0.0   \n",
       "6050               0.0            0.0           0.0            0.0   \n",
       "6052               0.0            0.0           0.0            0.0   \n",
       "6053               0.0            0.0           0.0            0.0   \n",
       "6054               0.0            1.0           0.0            0.0   \n",
       "...                ...            ...           ...            ...   \n",
       "142298             0.0            0.0           0.0            1.0   \n",
       "142299             0.0            0.0           0.0            1.0   \n",
       "142300             0.0            0.0           0.0            0.0   \n",
       "142301             0.0            0.0           0.0            1.0   \n",
       "142302             0.0            0.0           0.0            0.0   \n",
       "\n",
       "        WindDir9am_SSE  WindDir9am_SSW  WindDir9am_SW  WindDir9am_W  \\\n",
       "6049               0.0             0.0            0.0           0.0   \n",
       "6050               1.0             0.0            0.0           0.0   \n",
       "6052               0.0             0.0            0.0           0.0   \n",
       "6053               0.0             0.0            0.0           0.0   \n",
       "6054               0.0             0.0            0.0           0.0   \n",
       "...                ...             ...            ...           ...   \n",
       "142298             0.0             0.0            0.0           0.0   \n",
       "142299             0.0             0.0            0.0           0.0   \n",
       "142300             0.0             0.0            0.0           0.0   \n",
       "142301             0.0             0.0            0.0           0.0   \n",
       "142302             0.0             0.0            0.0           0.0   \n",
       "\n",
       "        WindDir9am_WNW  WindDir9am_WSW  \n",
       "6049               0.0             0.0  \n",
       "6050               0.0             0.0  \n",
       "6052               0.0             0.0  \n",
       "6053               1.0             0.0  \n",
       "6054               0.0             0.0  \n",
       "...                ...             ...  \n",
       "142298             0.0             0.0  \n",
       "142299             0.0             0.0  \n",
       "142300             0.0             0.0  \n",
       "142301             0.0             0.0  \n",
       "142302             0.0             0.0  \n",
       "\n",
       "[58080 rows x 48 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(labels = ['RainTomorrow'], axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6049      0.0\n",
       "6050      0.0\n",
       "6052      0.0\n",
       "6053      0.0\n",
       "6054      0.0\n",
       "         ... \n",
       "142298    0.0\n",
       "142299    0.0\n",
       "142300    0.0\n",
       "142301    0.0\n",
       "142302    0.0\n",
       "Name: RainTomorrow, Length: 58080, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['RainTomorrow']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37171, 48)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9293, 48)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11616, 48)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Reduction to keep 95% of the variance. Reducing 16 variables!\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37171, 33)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9293, 33)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11616, 33)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27180,  1790],\n",
       "       [ 4519,  3682]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pred = model_lr.predict(X_train)\n",
    "confusion_matrix(y_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.8302709101181028\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr_train = accuracy_score(y_train, X_train_pred)\n",
    "print(\"accuracy on training set: \", accuracy_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "best_model_lr = RandomizedSearchCV(model_lr, hyperparameters, random_state=42, n_iter=100, cv=5, verbose=0, n_jobs=-1)\n",
    "best_model_lr.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6909,  428],\n",
       "       [1099,  857]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_pred = best_model_lr.predict(X_val)\n",
    "confusion_matrix(y_val, X_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model's accuracy on validation set:  0.8356827719789088\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr_val = accuracy_score(y_val, X_val_pred)\n",
    "print(\"best model's accuracy on validation set: \", accuracy_lr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8508,  539],\n",
       "       [1414, 1155]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pred = best_model_lr.predict(X_test)\n",
    "confusion_matrix(y_test, X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ('Train', 'Test')\n",
    "y_pos = np.arange(len(models))\n",
    "accuracy = [accuracy_lr_train*100, accuracy_lr_test*100]\n",
    "\n",
    "plt.bar(y_pos, accuracy, align='center', alpha=0.5, color = 'black')\n",
    "plt.xticks(y_pos, models)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Logistic Regression')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model_svm = clf_svc = svm.SVC()\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27902,  1068],\n",
       "       [ 4570,  3631]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pred = model_svm.predict(X_train)\n",
    "confusion_matrix(y_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.848322617093971\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_train = accuracy_score(y_train, X_train_pred)\n",
    "print(\"accuracy on training set: \", accuracy_svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.792, total=   1.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.791, total=   1.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.791, total=   1.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.795, total=   1.9s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.791, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.808, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.820, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.811, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.817, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.819, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.789, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.789, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.789, total=   1.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.826, total=   2.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.815, total=   1.7s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.822, total=   1.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.821, total=   1.7s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.824, total=   1.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.832, total=   1.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.828, total=   1.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.823, total=   1.4s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.823, total=   1.4s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.825, total=   1.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.824, total=   1.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.824, total=   1.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.818, total=   1.4s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.824, total=   1.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.789, total=   1.4s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.790, total=   1.5s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.789, total=   1.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.811, total=   2.1s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.785, total=   2.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.804, total=   2.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.818, total=   2.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.800, total=   2.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.847, total=   1.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.843, total=   1.5s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.839, total=   1.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.837, total=   1.6s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.839, total=   1.6s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.835, total=   1.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.832, total=   1.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.831, total=   1.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.825, total=   1.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.828, total=   1.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.824, total=   1.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.818, total=   1.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.789, total=   1.4s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.790, total=   1.4s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.779, total=   2.7s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.765, total=   2.6s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.779, total=   2.7s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.780, total=   2.7s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.769, total=   2.7s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.848, total=   2.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.833, total=   2.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.837, total=   2.6s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.841, total=   2.5s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.835, total=   2.4s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.836, total=   1.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.836, total=   1.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.831, total=   1.7s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.825, total=   1.6s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.828, total=   1.7s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.836, total=   1.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.831, total=   1.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.829, total=   1.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.828, total=   1.4s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.827, total=   1.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.827, total=   1.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.824, total=   1.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.819, total=   1.4s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.826, total=   1.4s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.762, total=   3.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.756, total=   3.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.771, total=   3.1s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.773, total=   3.2s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.765, total=   3.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.825, total=   7.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.816, total=   9.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.818, total=   7.7s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.823, total=   7.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.812, total=   7.6s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.852, total=   2.9s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.846, total=   2.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.843, total=   2.7s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.836, total=   2.8s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.839, total=   2.7s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.835, total=   1.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.835, total=   1.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.829, total=   1.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.828, total=   1.6s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.829, total=   1.6s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.838, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.831, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.831, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.827, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.828, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "best_model_svm = GridSearchCV(model_svm, param_grid, verbose = 3) \n",
    "\n",
    "best_model_svm.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7050,  287],\n",
       "       [1039,  917]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_pred = best_model_svm.predict(X_val)\n",
    "confusion_matrix(y_val, X_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model's accuracy on validation set:  0.8573119552351232\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_val = accuracy_score(y_val, X_val_pred)\n",
    "print(\"best model's accuracy on validation set: \", accuracy_svm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8618,  429],\n",
       "       [1450, 1119]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pred = best_model_svm.predict(X_test)\n",
    "confusion_matrix(y_test, X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set:  0.8382403581267218\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_test = accuracy_score(y_test, X_test_pred)\n",
    "print(\"accuracy on test set: \", accuracy_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ('Train', 'Test')\n",
    "y_pos = np.arange(len(models))\n",
    "accuracy = [accuracy_svm_train*100, accuracy_svm_test*100]\n",
    "\n",
    "plt.bar(y_pos, accuracy, align='center', alpha=0.5, color = 'black')\n",
    "plt.xticks(y_pos, models)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Support Vector Machine')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ('Train', 'Test')\n",
    "y_pos = np.arange(len(models))\n",
    "accuracy = [79.4, 78.2]\n",
    "\n",
    "plt.bar(y_pos, accuracy, align='center', alpha=0.5, color = 'black')\n",
    "plt.xticks(y_pos, models)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Gradient Boost')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27560,  1410],\n",
       "       [ 4479,  3722]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pred = model_gb.predict(X_train)\n",
    "confusion_matrix(y_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set:  0.8415700411611202\n"
     ]
    }
   ],
   "source": [
    "accuracy_gb_train = accuracy_score(y_train, X_train_pred)\n",
    "print(\"accuracy on training set: \", accuracy_gb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=1 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=1, score=0.789, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10, score=0.789, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100, score=0.790, total=  18.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100, score=0.790, total=  17.9s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100, score=0.789, total=  18.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100, score=0.790, total=  20.6s\n",
      "[CV] learning_rate=0.001, max_depth=10, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100, score=0.790, total=  18.8s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=10, score=0.790, total=   2.8s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=10, score=0.789, total=   2.7s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=100, score=0.790, total=  28.9s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=100, score=0.790, total=  29.1s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=100, score=0.789, total=  26.9s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=100, score=0.790, total=  29.1s\n",
      "[CV] learning_rate=0.001, max_depth=100, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.001, max_depth=100, n_estimators=100, score=0.790, total=  29.5s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=1 .............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=1 .............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=1 .............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=1 .............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=1 .............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=10 ............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=10, score=0.790, total=   2.8s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=10 ............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=10, score=0.790, total=   2.8s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=10 ............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=10, score=0.789, total=   2.8s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=10 ............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=10 ............\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=100 ...........\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=100, score=0.790, total=  28.3s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=100 ...........\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=100, score=0.790, total=  28.0s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=100 ...........\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=100, score=0.789, total=  27.2s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=100 ...........\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=100, score=0.790, total=  30.0s\n",
      "[CV] learning_rate=0.001, max_depth=1000, n_estimators=100 ...........\n",
      "[CV]  learning_rate=0.001, max_depth=1000, n_estimators=100, score=0.790, total=  29.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=1, score=0.789, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=0.789, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10, score=0.790, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.821, total=  18.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.810, total=  18.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.814, total=  18.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.803, total=  18.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.819, total=  18.6s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=10, score=0.790, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=10, score=0.789, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=100, score=0.777, total=  28.0s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=100, score=0.750, total=  27.3s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=100, score=0.779, total=  27.2s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=100, score=0.777, total=  29.2s\n",
      "[CV] learning_rate=0.01, max_depth=100, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.01, max_depth=100, n_estimators=100, score=0.772, total=  29.7s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=1 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=10, score=0.789, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=10, score=0.790, total=   2.9s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=10 .............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=10, score=0.790, total=   3.0s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=100, score=0.782, total=  28.2s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=100, score=0.748, total=  28.0s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=100, score=0.781, total=  26.9s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=100, score=0.774, total=  29.3s\n",
      "[CV] learning_rate=0.01, max_depth=1000, n_estimators=100 ............\n",
      "[CV]  learning_rate=0.01, max_depth=1000, n_estimators=100, score=0.771, total=  29.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=1, score=0.789, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=1, score=0.790, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.811, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.815, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.818, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.799, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10, score=0.813, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.831, total=  19.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.820, total=  19.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.825, total=  19.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.808, total=  19.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.829, total=  19.1s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=10, score=0.777, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=10, score=0.748, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=10, score=0.781, total=   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=10, score=0.773, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=10, score=0.770, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=100, score=0.781, total=  22.1s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=100, score=0.746, total=  21.3s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=100, score=0.777, total=  21.0s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=100, score=0.772, total=  22.7s\n",
      "[CV] learning_rate=0.1, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=100, n_estimators=100, score=0.762, total=  22.5s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=1, score=0.789, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=1, score=0.790, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=10, score=0.780, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=10, score=0.746, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=10, score=0.782, total=   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=10, score=0.772, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=10, score=0.772, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=100, score=0.782, total=  21.7s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=100, score=0.743, total=  21.1s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=100, score=0.779, total=  20.7s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=100, score=0.770, total=  22.2s\n",
      "[CV] learning_rate=0.1, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=0.1, max_depth=1000, n_estimators=100, score=0.765, total=  22.4s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=1 ..................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=1, score=0.783, total=   0.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=1 ..................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=1, score=0.758, total=   0.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=1 ..................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=1, score=0.778, total=   0.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=1 ..................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=1, score=0.777, total=   0.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=1 ..................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=1, score=0.784, total=   0.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=10 .................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=10, score=0.496, total=   1.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=10 .................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=10, score=0.334, total=   1.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=10 .................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=10, score=0.439, total=   1.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=10 .................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=10, score=0.455, total=   1.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=10 .................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=10, score=0.513, total=   1.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=100 ................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=100, score=0.453, total=  17.3s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=100 ................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=100, score=0.293, total=  18.2s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=100 ................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=100, score=0.319, total=  17.8s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=100 ................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=100, score=0.510, total=  18.3s\n",
      "[CV] learning_rate=10, max_depth=10, n_estimators=100 ................\n",
      "[CV]  learning_rate=10, max_depth=10, n_estimators=100, score=0.344, total=  17.7s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=1 .................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=1, score=0.767, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=1 .................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=1, score=0.733, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=1 .................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=1, score=0.764, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=1 .................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=1, score=0.758, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=1 .................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=1, score=0.751, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=10 ................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=10, score=0.768, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=10 ................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=10, score=0.735, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=10 ................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=10, score=0.768, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=10 ................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=10, score=0.751, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=10 ................\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=10, score=0.756, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=100 ...............\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=100, score=0.772, total=   0.4s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=100 ...............\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=100, score=0.736, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=100 ...............\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=100, score=0.762, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=100 ...............\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=100, score=0.764, total=   0.4s\n",
      "[CV] learning_rate=10, max_depth=100, n_estimators=100 ...............\n",
      "[CV]  learning_rate=10, max_depth=100, n_estimators=100, score=0.759, total=   0.4s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=1 ................\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=1, score=0.769, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=1 ................\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=1, score=0.733, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=1 ................\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=1, score=0.765, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=1 ................\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=1, score=0.755, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=1 ................\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=1, score=0.748, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=10 ...............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=10, score=0.774, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=10 ...............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=10, score=0.734, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=10 ...............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=10, score=0.772, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=10 ...............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=10, score=0.752, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=10 ...............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=10, score=0.749, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=100 ..............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=100, score=0.772, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=100 ..............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=100, score=0.725, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=100 ..............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=100, score=0.766, total=   0.3s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=100 ..............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=100, score=0.762, total=   0.4s\n",
      "[CV] learning_rate=10, max_depth=1000, n_estimators=100 ..............\n",
      "[CV]  learning_rate=10, max_depth=1000, n_estimators=100, score=0.751, total=   0.4s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=1, score=0.776, total=   0.2s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=1, score=0.757, total=   0.2s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=1, score=0.777, total=   0.2s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=1, score=0.778, total=   0.2s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=1 .................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=1, score=0.787, total=   0.2s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=10, score=0.458, total=   1.8s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=10, score=0.465, total=   1.8s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=10, score=0.482, total=   1.8s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=10, score=0.280, total=   1.8s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=10 ................\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=10, score=0.286, total=   1.8s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=100, score=0.429, total=  17.7s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=100, score=0.421, total=  17.6s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=100, score=0.372, total=  17.9s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=100, score=0.227, total=  17.9s\n",
      "[CV] learning_rate=100, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=100, max_depth=10, n_estimators=100, score=0.301, total=  17.5s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=1, score=0.772, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=1, score=0.734, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=1, score=0.767, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=1, score=0.759, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=1 ................\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=1, score=0.753, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=10, score=0.764, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=10, score=0.728, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=10, score=0.768, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=10, score=0.758, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=10 ...............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=10, score=0.753, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=100, score=0.770, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=100, score=0.724, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=100, score=0.770, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=100, score=0.758, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=100, n_estimators=100 ..............\n",
      "[CV]  learning_rate=100, max_depth=100, n_estimators=100, score=0.757, total=   0.4s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=1, score=0.771, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=1, score=0.741, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=1, score=0.768, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=1, score=0.756, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=1 ...............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=1, score=0.754, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=10, score=0.770, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=10, score=0.722, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=10, score=0.767, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=10, score=0.759, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=10 ..............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=10, score=0.750, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=100, score=0.769, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=100, score=0.729, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=100, score=0.769, total=   0.3s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=100, score=0.762, total=   0.4s\n",
      "[CV] learning_rate=100, max_depth=1000, n_estimators=100 .............\n",
      "[CV]  learning_rate=100, max_depth=1000, n_estimators=100, score=0.766, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 225 out of 225 | elapsed: 23.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 10, 100],\n",
       "                         'max_depth': [10, 100, 1000],\n",
       "                         'n_estimators': [1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'learning_rate': [0.001, 0.01, 0.1, 10, 100],\n",
    "         'max_depth': [10, 100, 1000],\n",
    "         'n_estimators': [1, 10, 100]\n",
    "         }\n",
    "\n",
    "best_model_gb = GridSearchCV(model_gb, params, verbose = 3) \n",
    "\n",
    "best_model_gb.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7337,    0],\n",
       "       [  12, 1944]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_pred = best_model_gb.predict(X_val)\n",
    "confusion_matrix(y_val, X_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model's accuracy on validation set:  0.9987087054772409\n"
     ]
    }
   ],
   "source": [
    "accuracy_gb_val = accuracy_score(y_val, X_val_pred)\n",
    "print(\"best model's accuracy on validation set: \", accuracy_gb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8445,  602],\n",
       "       [1439, 1130]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pred = best_model_gb.predict(X_test)\n",
    "confusion_matrix(y_test, X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set:  0.8242940771349863\n"
     ]
    }
   ],
   "source": [
    "accuracy_gb_test = accuracy_score(y_test, X_test_pred)\n",
    "print(\"accuracy on test set: \", accuracy_gb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ('Train', 'Test')\n",
    "y_pos = np.arange(len(models))\n",
    "accuracy = [accuracy_gb_train*100, accuracy_gb_test*100]\n",
    "\n",
    "plt.bar(y_pos, accuracy, align='center', alpha=0.5, color = 'black')\n",
    "plt.xticks(y_pos, models)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Gradient Boost')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
